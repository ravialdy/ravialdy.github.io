<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="ravialdy/ravialdy.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="ravialdy/ravialdy.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2023-10-24T01:11:38+00:00</updated><id>ravialdy/ravialdy.github.io/feed.xml</id><title type="html">Ravialdy’s Blog</title><subtitle>Experienced AI Researcher and Data Scientist with over 3 years of experience in computer vision, machine learning, and AI model deployment. Passionate about solving complex problems and advancing the state of technology. </subtitle><entry><title type="html">Grad-CAM Demystified, Understanding the Magic Behind Visual Explanations in Neural Networks</title><link href="ravialdy/ravialdy.github.io/blogpost/2023/10/20/gradcam-howitworks.html" rel="alternate" type="text/html" title="Grad-CAM Demystified, Understanding the Magic Behind Visual Explanations in Neural Networks"/><published>2023-10-20T13:56:00+00:00</published><updated>2023-10-20T13:56:00+00:00</updated><id>ravialdy/ravialdy.github.io/blogpost/2023/10/20/gradcam-howitworks</id><content type="html" xml:base="ravialdy/ravialdy.github.io/blogpost/2023/10/20/gradcam-howitworks.html"><![CDATA[<h2 id="introduction">Introduction</h2> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/gradcam/gradcam_our_result-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/gradcam/gradcam_our_result-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/gradcam/gradcam_our_result-1400.webp"/> <img src="/assets/img/gradcam/gradcam_our_result.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Figure 1. Grad-CAM visualization that we will implement in this blogpost. </div> <p>Convolutional Neural Networks (CNNs) are amazing. They can recognize cats in pictures, help self-driving cars see, and even beat humans at games. But what most people see about neural networks is this, they’re like magic boxes: data goes in, and the answer comes out, without knowing what happens in between. So, how do we know what part of an image the network finds important for its decision? Introducing Grad-CAM method, a technique that helps us “see” what the network is looking at.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/gradcam/GradCAM-Example-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/gradcam/GradCAM-Example-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/gradcam/GradCAM-Example-1400.webp"/> <img src="/assets/img/gradcam/GradCAM-Example.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Figure 2. Example of how Grad-CAM visualization shows the important part for the model's decision on different classes (Image source : https://github.com/kazuto1011/grad-cam-pytorch). </div> <h2 id="what-is-grad-cam">What is Grad-CAM?</h2> <p>Grad-CAM stands for Gradient-weighted Class Activation Mapping. Why the name is like that? In short, we use gradient to help us understand how neural networks behave in certain circumstances, while activation here is analogous with the level of excitement or interest the neural network has when it comes to certain features used in recognizing the important part in the image (we will discuss in detail about it later). How it does that? Basically, Grad-CAM will create what we call a “heatmap.” Imagine you have your cat picture. Now, think of putting a see-through red paper over it. This red paper will have some areas darker and some areas lighter. The darker areas show where the neural network looked the most. Maybe the network looked a lot at the cat’s eyes and a little at the tail. This heatmap will help you “see” what parts of the picture made the neural network decide it’s looking at a cat. It’s like the network is saying, “Look, I think this is a cat because of these parts of the picture.”</p> <h2 id="the-core-idea">The Core Idea</h2> <p>Grad-CAM will use something called “gradients” which can tell us how much each neuron’s activity would need to change in order to affect the final decision (class scores or logits that are output by the neural network) of the model. The key intuition here is that if the gradient is large in magnitude, a small change in the neuron’s activity will have a significant impact on the final decision. Conversely, if the gradient is small, the neuron’s contribution to the final decision is relatively minor. Grad-CAM also often uses deeper layers in order to visualize important part of the image. In a CNN, the early layers usually can only understand simple things like edges or colors. The deeper you go, the more complex the things they understand, like ears or whiskers. Grad-CAM focuses on the last set of these layers because they understand both the important details (like whiskers) and the bigger picture (like the shape of a cat).</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/gradcam/gradcam_different_layers-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/gradcam/gradcam_different_layers-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/gradcam/gradcam_different_layers-1400.webp"/> <img src="/assets/img/gradcam/gradcam_different_layers.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Figure 3. Illustration of the effect of deeper layers towards Grad-CAM visualization. </div> <h2 id="how-does-it-work-in-quite-detail">How Does it Work in Quite Detail?</h2> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/gradcam/gradcam_detail_works-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/gradcam/gradcam_detail_works-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/gradcam/gradcam_detail_works-1400.webp"/> <img src="/assets/img/gradcam/gradcam_detail_works.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Figure 4. Overview Grad-CAM architecture. </div> <h3 id="step-1-backward-pass">Step 1: Backward Pass</h3> <p>First, we need to find out how much each part of our image contributed to the final decision. So, we go backward through the network, from the output (“this is a cat”) toward the input image. As we go back, we calculate something called gradients. Remember that the “gradient” of a neuron with respect to the final decision can give us a measure of sensitivity. Specifically, it tells us how much the final output (e.g., the probability score for the class “cat”) would change if the activity of that particular neuron were to change by a small amount. In mathematical terms, if \(y\) is the final output and \(A_{ij}^k\) is the activation of neuron \(k\) at position \((i, j)\) in some layer, then \(\frac{\partial y}{\partial A_{ij}^k}\) is the gradient that tells us the rate of change of \(y\) with respect to \(A_{ij}^k\).</p> <h3 id="step-2-average-pooling">Step 2: Average Pooling</h3> <p>We then average these gradients across the spatial dimensions (width and height) of each feature map. This gives us a single number for each feature map, which we call the “importance weight.”</p> <p>The math looks like this:</p> \[\alpha_{k}^{c} = \frac{1}{Z} \sum_{i} \sum_{j} \frac{\partial y^{c}}{\partial A_{i j}^{k}}\] <p>Here, \(\alpha_{k}^{c}\) is the importance weight for feature map \(k\) when identifying class \(c\).</p> <h3 id="step-3-weighted-sum">Step 3: Weighted Sum</h3> <p>Next, we take a weighted sum of our original feature maps, using these importance weights. This gives us a rough heatmap.</p> \[L_{\text{Grad-CAM}}^{c} = \text{ReLU}\left(\sum_{k} \alpha_{k}^{c} A^{k}\right)\] <h3 id="step-4-relu-activation">Step 4: ReLU Activation</h3> <p>Finally, we apply a ReLU (Rectified Linear Unit) function to this heatmap. Why? Because we’re only interested in the parts of the image that positively influence the final decision.</p> <h2 id="a-simple-pytorch-grad-cam-implementation">A Simple PyTorch Grad-CAM Implementation</h2> <p>To see Grad-CAM in action, let’s walk through a straightforward example using PyTorch. We’ll use a pretrained VGG16 model for this demonstration.</p> <p>First, make sure to install PyTorch if you haven’t already.</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip <span class="nb">install </span>torch torchvision
</code></pre></div></div> <h3 id="import-libraries">Import Libraries</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">torch</span>
<span class="kn">import</span> <span class="n">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="n">torchvision.models</span> <span class="k">as</span> <span class="n">models</span>
<span class="kn">import</span> <span class="n">torchvision.transforms</span> <span class="k">as</span> <span class="n">transforms</span>
<span class="kn">from</span> <span class="n">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
</code></pre></div></div> <h3 id="load-pretrained-model">Load Pretrained Model</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Load a pretrained VGG16 model
</span><span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="p">.</span><span class="nf">vgg16</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>
</code></pre></div></div> <h3 id="utility-function-to-get-model-features-and-gradients">Utility Function to Get Model Features and Gradients</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">typing</span> <span class="kn">import</span> <span class="n">Tuple</span>

<span class="k">def</span> <span class="nf">get_features_gradients</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">]:</span>
    <span class="sh">"""</span><span class="s">
    Forward pass to get the features and register hook to get gradients.
    
    Parameters:
    - model (nn.Module): Neural network model
    - x (torch.Tensor): Input image tensor
    
    Returns:
    - features (torch.Tensor): Extracted features from the last convolutional layer
    - gradients (torch.Tensor): Gradients w.r.t the features
    </span><span class="sh">"""</span>
    <span class="n">features</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="n">gradients</span> <span class="o">=</span> <span class="bp">None</span>
    
    <span class="k">def</span> <span class="nf">hook_feature</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">output</span><span class="p">):</span>
        <span class="k">nonlocal</span> <span class="n">features</span>
        <span class="n">features</span> <span class="o">=</span> <span class="n">output</span><span class="p">.</span><span class="nf">detach</span><span class="p">()</span>
        
    <span class="k">def</span> <span class="nf">hook_gradient</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">):</span>
        <span class="k">nonlocal</span> <span class="n">gradients</span>
        <span class="n">gradients</span> <span class="o">=</span> <span class="n">grad_output</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">detach</span><span class="p">()</span>
        
    <span class="c1"># Register hooks
</span>    <span class="n">handle_forward</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">features</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">].</span><span class="nf">register_forward_hook</span><span class="p">(</span><span class="n">hook_feature</span><span class="p">)</span>
    <span class="n">handle_backward</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">features</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">].</span><span class="nf">register_backward_hook</span><span class="p">(</span><span class="n">hook_gradient</span><span class="p">)</span>
    
    <span class="c1"># Forward and backward pass
</span>    <span class="n">model</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>
    <span class="n">output</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="c1"># Class-specific backprop
</span>    <span class="n">output</span><span class="p">.</span><span class="nf">backward</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nc">Tensor</span><span class="p">([[</span><span class="mi">1</span> <span class="k">if</span> <span class="n">idx</span> <span class="o">==</span> <span class="mi">243</span> <span class="k">else</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">output</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])]]))</span>
    
    <span class="c1"># Remove hooks
</span>    <span class="n">handle_forward</span><span class="p">.</span><span class="nf">remove</span><span class="p">()</span>
    <span class="n">handle_backward</span><span class="p">.</span><span class="nf">remove</span><span class="p">()</span>
    
    <span class="k">return</span> <span class="n">features</span><span class="p">,</span> <span class="n">gradients</span>
</code></pre></div></div> <h3 id="generate-grad-cam-heatmap">Generate Grad-CAM Heatmap</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">typing</span> <span class="kn">import</span> <span class="n">Tuple</span>

<span class="k">def</span> <span class="nf">generate_grad_cam</span><span class="p">(</span><span class="n">features</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">gradients</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">image_shape</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Generate Grad-CAM heatmap.

    Parameters:
    - features (torch.Tensor): Extracted features from the last convolutional layer
    - gradients (torch.Tensor): Gradients w.r.t the features
    - image_shape (Tuple[int, int]): Original shape of the input image (height, width)

    Returns:
    - torch.Tensor: Grad-CAM heatmap
    </span><span class="sh">"""</span>
    <span class="c1"># Global average pooling on gradients to get neuron importance
</span>    <span class="n">alpha</span> <span class="o">=</span> <span class="n">gradients</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">keepdim</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

    <span class="c1"># Weighted sum of feature maps based on neuron importance
</span>    <span class="n">weighted_features</span> <span class="o">=</span> <span class="n">features</span> <span class="o">*</span> <span class="n">alpha</span>

    <span class="c1"># ReLU applied on weighted combination of feature maps
</span>    <span class="n">heatmap</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="nf">relu</span><span class="p">(</span><span class="n">weighted_features</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span>
    
    <span class="c1"># Resizing the heatmap to original image size
</span>    <span class="n">heatmap</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="nf">interpolate</span><span class="p">(</span><span class="n">heatmap</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">image_shape</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="sh">'</span><span class="s">bilinear</span><span class="sh">'</span><span class="p">,</span> <span class="n">align_corners</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">heatmap</span>
</code></pre></div></div> <h3 id="function-to-overlay-heatmap-on-original-image">Function to Overlay Heatmap on Original Image</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">cv2</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="n">typing</span> <span class="kn">import</span> <span class="n">Union</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="k">def</span> <span class="nf">overlay_heatmap_on_image</span><span class="p">(</span><span class="n">image</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">Image</span><span class="p">.</span><span class="n">Image</span><span class="p">],</span> 
                             <span class="n">heatmap</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">],</span> 
                             <span class="n">alpha</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Overlay the Grad-CAM heatmap on the original image.
    
    Parameters:
    - image (np.ndarray or PIL.Image): Original input image
    - heatmap (Union[np.ndarray, torch.Tensor]): Grad-CAM heatmap
    - alpha (float): Weight of the heatmap when overlaying
    
    Returns:
    - np.ndarray: Image with heatmap overlaid
    </span><span class="sh">"""</span>
    <span class="c1"># Convert PIL image to numpy array if necessary
</span>    <span class="k">if</span> <span class="nf">isinstance</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">Image</span><span class="p">.</span><span class="n">Image</span><span class="p">):</span>
        <span class="n">image</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
    
    <span class="c1"># Convert torch.Tensor to numpy array if necessary
</span>    <span class="k">if</span> <span class="nf">isinstance</span><span class="p">(</span><span class="n">heatmap</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="n">heatmap</span> <span class="o">=</span> <span class="n">heatmap</span><span class="p">.</span><span class="nf">numpy</span><span class="p">()</span>
    
    <span class="c1"># Normalize the heatmap and convert to RGB format
</span>    <span class="n">heatmap_normalized</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">normalize</span><span class="p">(</span><span class="n">heatmap</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mi">255</span><span class="p">,</span> <span class="n">norm_type</span><span class="o">=</span><span class="n">cv2</span><span class="p">.</span><span class="n">NORM_MINMAX</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">cv2</span><span class="p">.</span><span class="n">CV_8U</span><span class="p">)</span>
    <span class="n">heatmap_colored</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">applyColorMap</span><span class="p">(</span><span class="n">heatmap_normalized</span><span class="p">,</span> <span class="n">cv2</span><span class="p">.</span><span class="n">COLORMAP_JET</span><span class="p">)</span>
    
    <span class="c1"># Resize heatmap to match the image size
</span>    <span class="n">heatmap_resized</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">resize</span><span class="p">(</span><span class="n">heatmap_colored</span><span class="p">,</span> <span class="p">(</span><span class="n">image</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">image</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
    
    <span class="c1"># Overlay heatmap on image
</span>    <span class="n">overlayed</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">addWeighted</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">heatmap_resized</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">overlayed</span>
</code></pre></div></div> <h3 id="function-to-visualize-heatmap">Function to Visualize Heatmap</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">typing</span> <span class="kn">import</span> <span class="n">Union</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="k">def</span> <span class="nf">visualize_heatmap</span><span class="p">(</span><span class="n">image</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">Image</span><span class="p">.</span><span class="n">Image</span><span class="p">],</span> 
                      <span class="n">heatmap</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span> 
                      <span class="n">figsize</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Visualize the original image, the Grad-CAM heatmap, and the overlayed image.
    
    Parameters:
    - image (Union[np.ndarray, Image.Image]): The original input image.
    - heatmap (torch.Tensor): The Grad-CAM heatmap.
    - figsize (Tuple[int, int]): The size of the figure for plotting.
    
    Returns:
    - None
    </span><span class="sh">"""</span>
    <span class="c1"># Normalize the heatmap for visualization
</span>    <span class="n">heatmap_normalized</span> <span class="o">=</span> <span class="n">heatmap</span><span class="p">.</span><span class="nf">squeeze</span><span class="p">().</span><span class="nf">cpu</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span>
    <span class="n">heatmap_normalized</span> <span class="o">=</span> <span class="p">(</span><span class="n">heatmap_normalized</span> <span class="o">-</span> <span class="n">heatmap_normalized</span><span class="p">.</span><span class="nf">min</span><span class="p">())</span> <span class="o">/</span> <span class="p">(</span><span class="n">heatmap_normalized</span><span class="p">.</span><span class="nf">max</span><span class="p">()</span> <span class="o">-</span> <span class="n">heatmap_normalized</span><span class="p">.</span><span class="nf">min</span><span class="p">())</span>
    
    <span class="c1"># Overlay the heatmap on the original image
</span>    <span class="n">overlayed_image</span> <span class="o">=</span> <span class="nf">overlay_heatmap_on_image</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">heatmap_normalized</span><span class="p">)</span>
    
    <span class="c1"># Create the plot
</span>    <span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="n">figsize</span><span class="p">)</span>
    
    <span class="n">plt</span><span class="p">.</span><span class="nf">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Original Image</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">imshow</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">image</span><span class="p">))</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">axis</span><span class="p">(</span><span class="sh">'</span><span class="s">off</span><span class="sh">'</span><span class="p">)</span>
    
    <span class="n">plt</span><span class="p">.</span><span class="nf">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Grad-CAM Heatmap</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">imshow</span><span class="p">(</span><span class="n">heatmap_normalized</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="sh">'</span><span class="s">jet</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">axis</span><span class="p">(</span><span class="sh">'</span><span class="s">off</span><span class="sh">'</span><span class="p">)</span>
    
    <span class="n">plt</span><span class="p">.</span><span class="nf">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Overlayed Image</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">imshow</span><span class="p">(</span><span class="n">cv2</span><span class="p">.</span><span class="nf">cvtColor</span><span class="p">(</span><span class="n">overlayed_image</span><span class="p">,</span> <span class="n">cv2</span><span class="p">.</span><span class="n">COLOR_BGR2RGB</span><span class="p">))</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">axis</span><span class="p">(</span><span class="sh">'</span><span class="s">off</span><span class="sh">'</span><span class="p">)</span>
    
    <span class="n">plt</span><span class="p">.</span><span class="nf">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div> <h3 id="putting-it-all-together">Putting it All Together</h3> <p>Now, let’s apply Grad-CAM on an example image.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Load and preprocess an example image (here, 'bull_mastiff.jpg' is an example image file)
</span><span class="n">input_image</span> <span class="o">=</span> <span class="n">Image</span><span class="p">.</span><span class="nf">open</span><span class="p">(</span><span class="sh">"</span><span class="s">/content/bull_mastiff.jpg</span><span class="sh">"</span><span class="p">).</span><span class="nf">resize</span><span class="p">((</span><span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">))</span>
<span class="n">preprocess</span> <span class="o">=</span> <span class="n">transforms</span><span class="p">.</span><span class="nc">Compose</span><span class="p">([</span>
    <span class="n">transforms</span><span class="p">.</span><span class="nc">ToTensor</span><span class="p">(),</span>
    <span class="n">transforms</span><span class="p">.</span><span class="nc">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="p">[</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">],</span> <span class="n">std</span><span class="o">=</span><span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">]),</span>
<span class="p">])</span>
<span class="n">input_tensor</span> <span class="o">=</span> <span class="nf">preprocess</span><span class="p">(</span><span class="n">input_image</span><span class="p">).</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Get features and gradients
</span><span class="n">features</span><span class="p">,</span> <span class="n">gradients</span> <span class="o">=</span> <span class="nf">get_features_gradients</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">input_tensor</span><span class="p">)</span>

<span class="c1"># Generate Grad-CAM heatmap
</span><span class="n">image_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">input_image</span><span class="p">.</span><span class="n">height</span><span class="p">,</span> <span class="n">input_image</span><span class="p">.</span><span class="n">width</span><span class="p">)</span>
<span class="n">heatmap</span> <span class="o">=</span> <span class="nf">generate_grad_cam</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">gradients</span><span class="p">,</span> <span class="n">image_shape</span><span class="p">)</span>

<span class="c1"># Visualize the heatmap
</span><span class="nf">visualize_heatmap</span><span class="p">(</span><span class="n">input_image</span><span class="p">,</span> <span class="n">heatmap</span><span class="p">)</span>
</code></pre></div></div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/gradcam/gradcam_our_result-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/gradcam/gradcam_our_result-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/gradcam/gradcam_our_result-1400.webp"/> <img src="/assets/img/gradcam/gradcam_our_result.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Figure 5. Grad-CAM visualization result. </div> <p>In this example, we focused on the ‘bull mastiff’ class, which corresponds to index 243 in the ImageNet dataset. You can replace this with the index for any other class you’re interested in.</p> <h2 id="conclusion">Conclusion</h2> <p>Grad-CAM is like understanding how exactly neural networks make a decision. It allows the network to tell us, “Hey, I think this is a cat because of these whiskers and this tail.” And it does this all without requiring any change to the existing model architecture and retraining the model, making it a powerful tool for understanding these complex networks.</p> <p>I hope this blog post has demystified Grad-CAM for you. It’s a very good visualization method that can explain the decision of complex neural networks, letting us see what’s happening under the hood.</p>]]></content><author><name></name></author><category term="blogpost"/><category term="Computer"/><category term="Vision"/><category term="(CV),"/><category term="GradCAM,"/><category term="Visualization"/><summary type="html"><![CDATA[Introduction]]></summary></entry><entry><title type="html">Understanding Phenomenal REINFORCE Policy Gradient Method</title><link href="ravialdy/ravialdy.github.io/blogpost/2023/10/15/reinforce-blog.html" rel="alternate" type="text/html" title="Understanding Phenomenal REINFORCE Policy Gradient Method"/><published>2023-10-15T13:56:00+00:00</published><updated>2023-10-15T13:56:00+00:00</updated><id>ravialdy/ravialdy.github.io/blogpost/2023/10/15/reinforce-blog</id><content type="html" xml:base="ravialdy/ravialdy.github.io/blogpost/2023/10/15/reinforce-blog.html"><![CDATA[<h2 id="introduction">Introduction</h2> <p>Welcome to my blog post! Today we’re going to discuss about a very fascinating topic in the world of AI and Reinforcement Learning (RL) — the Policy Gradient REINFORCE Method. This method is quite famous for solving some complex problems in RL. Don’t worry if you’re new to this field; I’ll try to keep things simple and easy to understand. First of all, I will be focusing on the background of the REINFORCE method and why it was proposed in the first place.</p> <h3 id="brief-recap-about-reinforcement-learning">Brief Recap about Reinforcement Learning</h3> <p>Before diving into the core method, it’s important to get some basics right. In RL, an agent (for simplicity, you can imagine this like a robot that learns something) interacts with an environment (like a maze). At each time \(t\), the agent is in a state \(s_t\), takes an action \(a_t\), and receives a reward \(r_t\).</p> <p>The agent follows a “policy” \(\pi(s, a)\), which tells it what action \(a\) to take when in state \(s\). This policy is controlled by some parameters \(\theta\), which we adjust to make the policy better. Here are the more formal definitions of important terms in RL:</p> <ul> <li> <p><strong>Environment</strong>: The space or setting in which the agent operates.</p> </li> <li> <p><strong>State</strong>: The condition of the environment at a given time point, often denoted as \(s\) or \(s_t\) to indicate its time-dependence.</p> </li> <li> <p><strong>Agent</strong>: An entity that observes the state of the environment and takes actions to achieve a specific objective.</p> </li> <li> <p><strong>Action</strong>: A specific operation that an agent can execute, typically denoted by \(a\) or \(a_t\).</p> </li> <li> <p><strong>Policy</strong>: A policy, denoted by \(\pi(a \mid s)\) or \(\pi(s, a)\), is a mapping from states to actions, or to probabilities of selecting each action.</p> </li> <li> <p><strong>Reward</strong>: A scalar value, often denoted by \(r\) or \(r_t\), that the environment returns in response to the agent’s action.</p> </li> </ul> <h3 id="what-are-we-trying-to-optimize">What Are We Trying to Optimize?</h3> <p>The ultimate goal in the RL method is to maximize the long-term reward. We often denote this as \(\rho(\pi)\). This is the average reward the agent expects to get over time while following policy \(\pi\).</p> <h2 id="the-problem-with-traditional-methods">The Problem with Traditional Methods</h2> <p>In RL, we often want a computer to learn how to make decisions by itself. For instance, think of a game where a robot must find its way out of a maze. The robot learns by trying different paths and seeing which ones get it out of the maze faster. Sounds simple, right? But when the maze is large and complicated, the number of decisions the robot must make becomes huge. This is where function approximators like neural networks come in handy; they help the robot generalize from its experience to make better decisions.</p> <p>For a long time, people used something called a “value-function approach” to do this. In this approach, all the effort is put into calculating a value for each decision or “action” the robot can make. The robot then chooses the action with the highest value. However, this approach has some downsides:</p> <ul> <li> <p><strong>Deterministic Policies</strong>: The traditional method is good for making a fixed decision, but sometimes we want the robot to be a bit random. Why? Because the best decision can depend on chance or unknown factors.</p> </li> <li> <p><strong>Sensitive Choices</strong>: A tiny change in the calculated value can dramatically change the action taken by the robot. This is risky because we want the robot to learn stable behavior.</p> </li> <li> <p><strong>Convergence Issues</strong>: Looks like a fancy term, but it simply means that using the value-function approach does not always guarantee that the robot will find the best way to act in all situations.</p> </li> </ul> <h2 id="the-policy-gradient-theorem">The Policy Gradient Theorem</h2> <p>Before we delve into the details of REINFORCE algorithm, let’s clarify why policy gradients can be a game-changer in the world of RL. The reason for this is that REINFORCE itself belongs to this approach. Unlike traditional value-based methods which assess the “goodness” of states or state-action pairs, policy gradients aim to directly tweak the policy—a mapping from states to actions. This approach can avoid at least three potential problems:</p> <ul> <li> <p><strong>Curse of Dimensionality</strong>: Value-based methods often suffer from the “curse of dimensionality.” The state-action space can grow exponentially with the number of features describing the state and the range of actions available. This makes the computational cost expensive.</p> </li> <li> <p><strong>Non-Markovian Environments</strong>: In some cases, the environment is not following the Markov Property, where the future state depends only on the current state and action. In that case, using a value function to capture the “goodness” of a state can be misleading or incomplete.</p> </li> <li> <p><strong>Exploration vs. Exploitation</strong>: Value-based methods often cause the agent to stick to known high-value states and actions, missing out on potentially better options. While exploration strategies exist, they add another layer of complexity to the algorithm.</p> </li> </ul> <p>In simpler terms, by focusing directly on optimizing the policy, policy gradient methods can sidestep many of these issues. They are particularly well-suited for high-dimensional or continuous action spaces, can naturally accommodate stochastic policies, and are less sensitive to the challenges associated with value function approximation.</p> <h3 id="the-formal-objective">The Formal Objective</h3> <p>The objective is to maximize the expected return \(\rho(\pi)\), defined as the average sum of rewards an agent can expect to receive while following a specific policy \(\pi\).</p> \[\max_{\theta} \mathbb{E}_{\pi_{\theta}}\left[\sum_{t=0}^{T-1} \gamma^{t} r_{t}\right]\] <p>In this equation, \(\gamma\) is the discount factor, \(\theta\) are the parameters governing the policy \(\pi\), and \(T\) is the time horizon.</p> <h3 id="the-policy-gradient-theorem-in-detail">The Policy Gradient Theorem in Detail</h3> <p>To find the maximum of this objective function, we need its gradient concerning \(\theta\). The Policy Gradient Theorem provides this invaluable piece of information. Formally, it is expressed as:</p> \[\frac{\partial \rho(\pi)}{\partial \theta} = \sum_{s} d^{\pi}(s) \sum_{a} \frac{\partial \pi(s, a)}{\partial \theta} Q^{\pi}(s, a)\] <p>Here, \(d^{\pi}(s)\) represents the stationary distribution of states when following policy \(\pi\), and \(Q^{\pi}(s, a)\) is the expected return of taking action \(a\) in state \(s\) while following \(\pi\).</p> <p>This equation essentially tells us how a minute change in \(\theta\) will influence the expected return \(\rho(\pi)\).</p> <h3 id="the-log-derivative-trick">The Log-Derivative Trick</h3> <p>For effective computation of the gradient, the log-derivative trick is often employed. This trick allows us to rephrase the gradient as an expectation:</p> \[\frac{\partial \rho(\pi)}{\partial \theta} = \mathbb{E}_{\tau \sim \pi_{\theta}} \left[ \sum_{t=0}^{T-1} \nabla_{\theta} \log \pi_{\theta}(a_t \mid s_t) Q^{\pi}(s_t, a_t) \right]\] <p>This is essentially a restatement of the gradient of a function with respect to its logarithm, which can be formally described as:</p> \[\nabla_{\theta} \pi(a \mid s) = \pi(a \mid s) \nabla_{\theta} \log \pi(a \mid s)\] <p>To prove this, we’ll take the derivative of \(\log \pi(a \mid s)\) with respect to \(\theta\):</p> \[\nabla_{\theta} \log \pi(a \mid s) = \frac{\nabla_{\theta} \pi(a \mid s)}{\pi(a \mid s)}\] <p>Rearranging the terms gives:</p> \[\nabla_{\theta} \pi(a \mid s) = \pi(a \mid s) \nabla_{\theta} \log \pi(a \mid s)\] <p>Now, let’s see how this trick fits into the policy gradient equation. The original policy gradient theorem can be expressed as:</p> \[\frac{\partial \rho(\pi)}{\partial \theta} = \sum_{s} d^{\pi}(s) \sum_{a} \nabla_{\theta} \pi(s, a) Q^{\pi}(s, a)\] <p>Here, \(d^{\pi}(s)\) represents the stationary distribution of states when following the policy \(\pi\).</p> <p>When you apply the Log-Derivative Trick to \(\nabla_{\theta} \pi(s, a)\), it becomes \(\pi(s, a) \nabla_{\theta} \log \pi(s, a)\). Substituting this into the policy gradient theorem, and then rewriting the sum as an expectation, we obtain:</p> \[\frac{\partial \rho(\pi)}{\partial \theta} = \mathbb{E}_{\tau \sim \pi_{\theta}} \left[ \sum_{t=0}^{T-1} \nabla_{\theta} \log \pi_{\theta}(a_t \mid s_t) Q^{\pi}(s_t, a_t) \right]\] <p>In this expression, \(\tau\) symbolizes a trajectory, and \(\nabla_{\theta} \log \pi_{\theta}(a_t \mid s_t)\) is the gradient of the log-probability of the action taken at time \(t\).</p> <p>This brings us to the policy gradient equation that I mentioned earlier. But why is this necessary? Computing gradients directly can be computationally expensive or even infeasible, especially when you are dealing with complex policies parameterized by neural networks.</p> <p>Let’s say you have a term like \(\pi(a \mid s)\) that depends on some parameters \(\theta\). Taking the derivative of this term directly with respect to \(\theta\) might be challenging. However, the Log-Derivative Trick provides a workaround. It transforms this term into:</p> \[\nabla_{\theta} \pi(a \mid s) = \pi(a \mid s) \nabla_{\theta} \log \pi(a \mid s)\] <p>Notice that \(\nabla_{\theta} \log \pi(a \mid s)\) is usually easier to compute. Also, this trick allows us to rephrase the Policy Gradient Theorem in a more computationally friendly manner.</p> <h3 id="why-should-we-care-about-policy-gradients">Why Should We Care About Policy Gradients?</h3> <ol> <li> <p><strong>Direct Optimization</strong>: Unlike value-based methods, policy gradients directly tweak what actually matters—the policy itself.</p> </li> <li> <p><strong>Stochasticity Handling</strong>: Policy gradients can optimize stochastic policies, crucial for situations where the optimal action can differ due to inherent randomness.</p> </li> <li> <p><strong>Sample Efficiency</strong>: Because the focus is on policy improvement, fewer samples are often required to learn a good policy, making the method generally more efficient.</p> </li> </ol> <p>By understanding the Policy Gradient Theorem and its underlying principles, you’ll find that it’s a fundamental building block for more advanced algorithms in the RL domain. Not only does it provide a method to directly optimize the policy, but it also offers the flexibility, stability, and efficiency required for real-world applications.</p> <h2 id="introducing-reinforce-algorithm">Introducing REINFORCE Algorithm</h2> <p>After understanding the power and flexibility of Policy Gradient methods, it’s time to delve into one of its most famous implementations: the REINFORCE algorithm which stands for REward Increment = Nonnegative Factor x Offset Reinforcement x Characteristic Eligibility, this algorithm is not just a fancy acronym; it’s often considered as one of the fundamental building block in the world of Reinforcement Learning.</p> <h3 id="main-idea-of-reinforce">Main Idea of REINFORCE</h3> <p>Remember that the Policy Gradient methods aim to optimize the policy in a way that increases the expected return from any state \(s\). However, calculating the true gradient of this expected return is often computationally infeasible or requires a model of the environment, which we usually don’t have. REINFORCE is one of the Policy Gradient algorithms that makes us possible to directly optimizing the policy function \(\pi(a \mid s)\) to maximize the cumulative reward. While there are many algorithms under the Policy Gradient category, REINFORCE stands out for its simplicity and directness in estimating the gradient.</p> <p>The core idea of REINFORCE that differentiate it with other methods is in its utilization of Monte Carlo methods to estimate the gradients needed for policy optimization. By taking sample paths through the state and action space, REINFORCE avoids the need for a model of the environment and sidesteps the computational bottleneck of calculating the true gradients. This is particularly useful when the state and/or action spaces are large or continuous, making other methods infeasible.</p> <h3 id="reinforce--policy-gradient-theorem">REINFORCE &amp; Policy Gradient Theorem</h3> <p>Recall that the Policy Gradient Theorem provides an expression for the gradient of the expected return with respect to the policy parameters. REINFORCE directly employs this theorem but takes it a step further by providing a practical way to estimate this gradient through sampling. The mathematical equation for obtaining expected return \(J(\theta)\) using this theorem can be written as:</p> \[\nabla J(\theta) = \mathbb{E}_{\pi_{\theta}} \left[ \sum_{t=0}^{T-1} \nabla_{\theta} \log \pi_{\theta}(A_t \mid S_t) Q^{\pi}(S_t, A_t) \right]\] <p>REINFORCE simplifies this expression by utilizing the Monte Carlo estimate for \(Q^{\pi}(S_t, A_t)\), which is the sampled return \(G_t\):</p> \[\nabla J(\theta) = \mathbb{E}_{\pi_{\theta}} \left[ \sum_{t=0}^{T-1} \nabla_{\theta} \log \pi_{\theta}(A_t \mid S_t) G_t \right]\] <p>In essence, REINFORCE is a concrete implementation of the Policy Gradient method that uses Monte Carlo sampling to estimate the otherwise intractable or unknown quantities in the Policy Gradient Theorem. By doing so, it provides a computationally efficient, model-free method to optimize policies in complex environments.</p> <h3 id="mathematical-details-of-reinforce">Mathematical Details of REINFORCE</h3> <p>The REINFORCE algorithm can be understood through a sequence of mathematical steps, which are as follows:</p> <ol> <li> <p><strong>Initialize Policy Parameters</strong>: Randomly initialize the policy parameters \(\theta\).</p> </li> <li> <p><strong>Generate Episode</strong>: Using the current policy \(\pi_\theta\), generate an episode \(S_1, A_1, R_2, \ldots, S_T\).</p> </li> <li><strong>Compute Gradients</strong>: For each step \(t\) in the episode, <ul> <li>Compute the return \(G_t\).</li> <li>Compute the policy gradient \(\Delta \theta_t = \alpha \gamma^t G_t \nabla_\theta \log \pi_\theta(A_t \mid S_t)\).</li> </ul> </li> <li><strong>Update Policy</strong>: Update the policy parameters \(\theta\) using \(\Delta \theta\).</li> </ol> <p>The key equation that governs this update is:</p> \[\nabla J(\theta) = \mathbb{E}_{\pi_\theta} \left[ \sum_{t=0}^{T-1} \nabla_\theta \log \pi_\theta(A_t \mid S_t) G_t \right]\] <p>Here, \(G_t\) is the return obtained using a Monte Carlo estimate, providing a sample-based approximation of \(Q^\pi(S_t, A_t)\).</p> <h3 id="conclusion-and-limitations">Conclusion and Limitations</h3> <p>While REINFORCE is oftenly used for its simplicity and directness, it’s also essential to recognize its limitations. The method tends to have high variance in its gradient estimates, which could lead to unstable training. However, various techniques, like using a baseline or employing advanced variance reduction methods, can alleviate these issues to some extent.</p> <p>REINFORCE is often the easy choice when you need a simple yet effective method for policy optimization, especially in high-dimensional or continuous action spaces.</p>]]></content><author><name></name></author><category term="blogpost"/><category term="Reinforcement"/><category term="Learning"/><category term="(RL),"/><category term="REINFORCE,"/><category term="Policy"/><category term="Gradient"/><summary type="html"><![CDATA[Introduction]]></summary></entry><entry><title type="html">What are JAX and Flax? Why those Deep Learning Frameworks can be Very Important?</title><link href="ravialdy/ravialdy.github.io/blogpost/2023/10/05/jaxflax.html" rel="alternate" type="text/html" title="What are JAX and Flax? Why those Deep Learning Frameworks can be Very Important?"/><published>2023-10-05T13:56:00+00:00</published><updated>2023-10-05T13:56:00+00:00</updated><id>ravialdy/ravialdy.github.io/blogpost/2023/10/05/jaxflax</id><content type="html" xml:base="ravialdy/ravialdy.github.io/blogpost/2023/10/05/jaxflax.html"><![CDATA[<h1 id="understanding-jax-and-flax">Understanding JAX and Flax!</h1> <p>Hello, everyone! Today, we will learn about two powerful tools for machine learning: JAX and Flax. These frameworks can be much faster than the common ones, such as Pytorch and Tensorflow. JAX helps us with fast math calculations, and Flax makes it easier to build neural networks. We’ll use both to make a simple image classifier for handwritten digits.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/jax-flax1-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/jax-flax1-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/jax-flax1-1400.webp"/> <img src="/assets/img/jax-flax1.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Figure 1. JAX vs. Tensorflow Speed Performance on Simple MNIST Image Classification Dataset </div> <h2 id="table-of-contents">Table of Contents</h2> <ol> <li><a href="#introduction">Introduction</a> <ul> <li><a href="#whats-the-issue-with-existing-frameworks">Issues with Existing Frameworks</a></li> </ul> </li> <li><a href="#so,-why-using-jax-and-flax">So, Why Using JAX and Flax?</a> <ul> <li><a href="#so-what-is-just-in-time-compilation">What is Just-In-Time Compilation?</a></li> <li><a href="#why-flax">Why Flax?</a></li> </ul> </li> <li><a href="#what-youll-learn">What You’ll Learn</a> <ul> <li><a href="#what-is-jax">JAX Explained</a></li> <li><a href="#what-is-flax">Flax Explained</a></li> </ul> </li> <li><a href="#jax-and-flax-w-mnist-image-classification">JAX and Flax Implementation w/ MNIST Image Classification</a></li> </ol> <h2 id="introduction">Introduction</h2> <p>Before diving into the technical details, let’s discuss why we even need frameworks like JAX and Flax when we already have powerful libraries like PyTorch and TensorFlow.</p> <h3 id="whats-the-issue-with-existing-frameworks">What’s the Issue with Existing Frameworks?</h3> <p>Don’t get me wrong—PyTorch and TensorFlow are great. They are versatile, powerful, and have huge communities. However, they can be a bit rigid for some research needs:</p> <ul> <li><strong>Not So Easy to Customize</strong>: If you need to modify the behavior of the training loop or gradient calculations, you might find it challenging.</li> <li><strong>Debugging</strong>: Debugging can be hard, especially when computation graphs become complex.</li> </ul> <h2 id="so-why-using-jax-and-flax">So, Why Using JAX and Flax?</h2> <p>JAX is like NumPy which means that JAX’s features is its NumPy-compatible API allowing for easy transition from NumPy to JAX for numerical operations, but supercharged:</p> <ul> <li><strong>Flexibility</strong>: JAX is functional and allows for more fine-grained control, making it highly customizable.</li> <li><strong>Performance</strong>: With its just-in-time compilation, JAX can optimize your code for high-speed numerical computing.</li> </ul> <p>In many cases, it would make sense to use jax.numpy (often imported as jnp) instead of ordinary NumPy to take advantage of JAX’s features like automatic differentiation and GPU acceleration.</p> <h3 id="why-flax">Why Flax?</h3> <p>Flax is like the cherry on top of JAX:</p> <ul> <li><strong>Simplicity</strong>: Building neural networks becomes straightforward.</li> <li><strong>Extendable</strong>: Designed with research in mind, you can easily add unconventional elements to your network or training loop.</li> </ul> <h2 id="what-youll-learn">What You’ll Learn</h2> <ul> <li>What are JAX and Flax?</li> <li>How to install them</li> <li>Building a simple CNN model for MNIST image classification</li> </ul> <h3 id="what-is-jax">What is JAX?</h3> <p>JAX is a library that helps us do fast numerical operations. It can automatically make our code run faster and allows us to use the GPU easily by utilizing Just-In-Time (JIT) Compilation. It is widely used in research for its flexibility and speed.</p> <h3 id="so-what-is-just-in-time-compilation">So, what is Just-In-Time Compilation?</h3> <p>Imagine you’re a chef, and you have a recipe (your code). Traditional Python executes this recipe step-by-step, which is time-consuming. JIT compilation is like having an assistant chef who learns from watching you and then can perform the entire recipe in a much more optimized manner. This is particularly beneficial for repetitive tasks like the training loops in machine learning models.</p> <p>In my experience, after applying JIT compilation properly, JAX outperformed TensorFlow and Pytorch in training speed, making it highly efficient for machine learning tasks. While JAX is powerful, it also requires careful coding practices. For example, to make full use of JIT compilation, it is crucial to avoid changing the code inside the training loop to prevent re-compilation, which can slow down the training process. Once you grasp these nuances, harnessing JAX’s full power becomes straightforward.</p> <h3 id="what-is-flax">What is Flax?</h3> <p>Flax is built on top of JAX and provides a simple way to build and train neural networks. It is designed to be flexible, making it a good choice for research projects.</p> <h2 id="jax-and-flax-w-mnist-image-classification">JAX and Flax w/ MNIST Image Classification</h2> <p>Let’s go into simple practical implementation on MNIST dataset. Before you build a skyscraper, you need to know how to make a small house. The same goes for machine learning. Understanding how to build a simple image classifier can give you the foundation you need to tackle more complex problems later. MNIST Image Classification is a simple but fundamental task in machine learning. It gives us a perfect playground to explore JAX and Flax without getting lost in the complexity of the task itself.</p> <h3 id="installing-jax-and-flax">Installing JAX and Flax</h3> <p>First, let’s install JAX and Flax. Open your terminal and run:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip <span class="nb">install</span> <span class="nt">--upgrade</span> jax jaxlib
pip <span class="nb">install </span>flax
</code></pre></div></div> <h3 id="import-libraries">Import Libraries</h3> <p>Let’s import all the libraries we need.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">jax</span>
<span class="kn">import</span> <span class="n">flax</span>
<span class="kn">import</span> <span class="n">jax.numpy</span> <span class="k">as</span> <span class="n">jnp</span>
<span class="kn">from</span> <span class="n">flax</span> <span class="kn">import</span> <span class="n">linen</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="n">jax</span> <span class="kn">import</span> <span class="n">random</span>
<span class="kn">from</span> <span class="n">tensorflow.keras</span> <span class="kn">import</span> <span class="n">datasets</span>
</code></pre></div></div> <h3 id="prepare-the-data">Prepare the Data</h3> <p>We’ll use the MNIST dataset, which is a set of 28x28 grayscale images of handwritten digits. We normalize the images by dividing by 255, as this scales the pixel values between 0 and 1, which generally helps the model to learn more efficiently.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="n">train_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">),</span> <span class="p">(</span><span class="n">test_images</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">)</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">.</span><span class="n">mnist</span><span class="p">.</span><span class="nf">load_data</span><span class="p">()</span>

<span class="c1"># Normalize and reshape the data using JAX's NumPy
</span><span class="n">train_images</span> <span class="o">=</span> <span class="n">jnp</span><span class="p">.</span><span class="nf">expand_dims</span><span class="p">(</span><span class="n">train_images</span> <span class="o">/</span> <span class="mf">255.0</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">).</span><span class="nf">astype</span><span class="p">(</span><span class="n">jnp</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">test_images</span> <span class="o">=</span> <span class="n">jnp</span><span class="p">.</span><span class="nf">expand_dims</span><span class="p">(</span><span class="n">test_images</span> <span class="o">/</span> <span class="mf">255.0</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">).</span><span class="nf">astype</span><span class="p">(</span><span class="n">jnp</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
</code></pre></div></div> <h3 id="create-the-model">Create the Model</h3> <p>Now let’s build a simple Convolutional Neural Network (CNN) using Flax.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Define the CNN model using Flax
</span><span class="k">class</span> <span class="nc">CNN</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    A simple CNN model for MNIST classification.
    </span><span class="sh">"""</span>
    <span class="nd">@nn.compact</span>
    <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">jnp</span><span class="p">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">jnp</span><span class="p">.</span><span class="n">ndarray</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Conv</span><span class="p">(</span><span class="n">features</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nf">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nf">avg_pool</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">window_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">strides</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Conv</span><span class="p">(</span><span class="n">features</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nf">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nf">avg_pool</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">window_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">strides</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="nf">reshape</span><span class="p">((</span><span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="n">features</span><span class="o">=</span><span class="mi">256</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nf">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="n">features</span><span class="o">=</span><span class="mi">10</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">nn</span><span class="p">.</span><span class="nf">log_softmax</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</code></pre></div></div> <h3 id="initialize-the-model">Initialize the Model</h3> <p>Before using our model, we need to initialize it. Initialization is crucial because it sets the initial random weights of the model, which will be updated during training.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">key</span> <span class="o">=</span> <span class="n">random</span><span class="p">.</span><span class="nc">PRNGKey</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="nc">CNN</span><span class="p">()</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">jnp</span><span class="p">.</span><span class="nf">ones</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">jnp</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">params</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">init</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
</code></pre></div></div> <h3 id="training">Training</h3> <p>Now, let’s train the model. But first, let’s initialize the optimizer. We will use the Adam optimizer provided by Optax. Optax is a flexible and extensible optimization library that provides a wide range of optimization algorithms.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Initialize the optimizer
</span><span class="kn">import</span> <span class="n">optax</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optax</span><span class="p">.</span><span class="nf">adam</span><span class="p">(</span><span class="mf">0.001</span><span class="p">)</span>
<span class="n">opt_state</span> <span class="o">=</span> <span class="n">optimizer</span><span class="p">.</span><span class="nf">init</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
</code></pre></div></div> <p>We won’t go into detail about training loops here, but you can use JAX’s <code class="language-plaintext highlighter-rouge">grad</code> function to compute gradients and update the model weights. We use JAX’s <code class="language-plaintext highlighter-rouge">jit</code> function to compile the <code class="language-plaintext highlighter-rouge">train_step</code> function, speeding up our training loop. Just-In-Time (JIT) compilation improves the performance by compiling Python functions to optimized machine code at runtime.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">jax</span> <span class="kn">import</span> <span class="n">grad</span><span class="p">,</span> <span class="n">jit</span><span class="p">,</span> <span class="n">value_and_grad</span>
<span class="kn">from</span> <span class="n">jax.scipy.special</span> <span class="kn">import</span> <span class="n">logsumexp</span>

<span class="k">def</span> <span class="nf">loss_fn</span><span class="p">(</span><span class="n">params</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span> <span class="n">images</span><span class="p">:</span> <span class="n">jnp</span><span class="p">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">labels</span><span class="p">:</span> <span class="n">jnp</span><span class="p">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Computes the loss between the predicted labels and true labels.
    </span><span class="sh">"""</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="nc">CNN</span><span class="p">().</span><span class="nf">apply</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">images</span><span class="p">)</span>
    <span class="n">logprobs</span> <span class="o">=</span> <span class="n">logits</span> <span class="o">-</span> <span class="nf">logsumexp</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="k">return</span> <span class="o">-</span><span class="n">jnp</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">jnp</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">logprobs</span> <span class="o">*</span> <span class="n">labels</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">))</span>

<span class="nd">@jit</span>
<span class="k">def</span> <span class="nf">train_step</span><span class="p">(</span><span class="n">opt_state</span><span class="p">:</span> <span class="n">optax</span><span class="p">.</span><span class="n">OptState</span><span class="p">,</span> <span class="n">params</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span> <span class="n">images</span><span class="p">:</span> <span class="n">jnp</span><span class="p">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">labels</span><span class="p">:</span> <span class="n">jnp</span><span class="p">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Performs a single training step.
    </span><span class="sh">"""</span>
    <span class="n">loss</span><span class="p">,</span> <span class="n">grads</span> <span class="o">=</span> <span class="nf">value_and_grad</span><span class="p">(</span><span class="n">loss_fn</span><span class="p">)(</span><span class="n">params</span><span class="p">,</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
    <span class="n">updates</span><span class="p">,</span> <span class="n">new_opt_state</span> <span class="o">=</span> <span class="n">optimizer</span><span class="p">.</span><span class="nf">update</span><span class="p">(</span><span class="n">grads</span><span class="p">,</span> <span class="n">opt_state</span><span class="p">)</span>
    <span class="n">new_params</span> <span class="o">=</span> <span class="n">optax</span><span class="p">.</span><span class="nf">apply_updates</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">updates</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">new_opt_state</span><span class="p">,</span> <span class="n">new_params</span><span class="p">,</span> <span class="n">loss</span>
</code></pre></div></div> <h3 id="pre-compiling-functions-for-faster-execution">Pre-Compiling Functions for Faster Execution</h3> <p>You might have noticed a somewhat unusual block of code right before our training loop:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Pre-compile functions
# Use a small subset of data to trigger JIT compilation
</span><span class="n">sample_images</span> <span class="o">=</span> <span class="n">jnp</span><span class="p">.</span><span class="nf">ones</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">jnp</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">sample_labels</span> <span class="o">=</span> <span class="n">jnp</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">jnp</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">jit_loss_fn</span> <span class="o">=</span> <span class="nf">jit</span><span class="p">(</span><span class="n">loss_fn</span><span class="p">)</span>
<span class="n">jit_train_step</span> <span class="o">=</span> <span class="nf">jit</span><span class="p">(</span><span class="n">train_step</span><span class="p">)</span>

<span class="c1"># Trigger JIT compilation
</span><span class="n">_</span> <span class="o">=</span> <span class="nf">jit_loss_fn</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">sample_images</span><span class="p">,</span> <span class="n">sample_labels</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="nf">jit_train_step</span><span class="p">(</span><span class="n">opt_state</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">sample_images</span><span class="p">,</span> <span class="n">sample_labels</span><span class="p">)</span>
</code></pre></div></div> <p>What’s going on with the code above? This block of code is a technique to “warm up” or pre-compile our JAX functions, so they run faster during our training loop.</p> <p>Small Subset of Data: We create a small subset of dummy data, sample_images and sample_labels, that matches the shape and type of our real data. JIT Compilation: We then use JAX’s jit function to indicate that loss_fn and train_step should be JIT compiled. Trigger Compilation: Finally, we run these JIT-compiled functions once using our dummy data. This step is crucial as it triggers the JIT compilation process, converting our Python functions into highly optimized machine code.</p> <h3 id="why-do-we-need-this">Why Do We Need This?</h3> <p>JAX uses Just-In-Time (JIT) compilation to optimize our code. JIT compilation works by looking at the operations in our functions and creating an optimized version of these functions. However, JIT compilation itself takes time. By pre-compiling, we do this step before entering our training loop, ensuring that our code runs at maximum speed when it matters the most.</p> <p>This pre-compilation step is particularly helpful in scenarios where the training loop has to run multiple times, helping us save time in the long run.</p> <p>Next, let’s divide the training data into training and validation sets:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="c1"># Split the training data into training and validation sets
</span><span class="n">train_images</span><span class="p">,</span> <span class="n">val_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">val_labels</span> <span class="o">=</span> <span class="nf">train_test_split</span><span class="p">(</span><span class="n">train_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># One-hot encode labels
</span><span class="n">train_labels_onehot</span> <span class="o">=</span> <span class="n">jax</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nf">one_hot</span><span class="p">(</span><span class="n">train_labels</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">val_labels_onehot</span> <span class="o">=</span> <span class="n">jax</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nf">one_hot</span><span class="p">(</span><span class="n">val_labels</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
</code></pre></div></div> <p>Now we can write the training loop.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">pickle</span>
<span class="kn">import</span> <span class="n">time</span>

<span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span>

<span class="c1"># Initialize variables to keep track of best model and performance
</span><span class="n">best_val_loss</span> <span class="o">=</span> <span class="nf">float</span><span class="p">(</span><span class="sh">'</span><span class="s">inf</span><span class="sh">'</span><span class="p">)</span>
<span class="n">best_params</span> <span class="o">=</span> <span class="bp">None</span>

<span class="c1"># Lists to keep track of loss values for plotting
</span><span class="n">train_losses</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">val_losses</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
    <span class="c1"># Training loop
</span>    <span class="n">train_loss_epoch</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">train_images</span><span class="p">),</span> <span class="n">batch_size</span><span class="p">):</span>
        <span class="n">batch_images</span> <span class="o">=</span> <span class="n">jnp</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">train_images</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">])</span>
        <span class="n">batch_labels</span> <span class="o">=</span> <span class="n">jnp</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">train_labels_onehot</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">])</span>
        <span class="n">opt_state</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="nf">train_step</span><span class="p">(</span><span class="n">opt_state</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">batch_images</span><span class="p">,</span> <span class="n">batch_labels</span><span class="p">)</span>
        <span class="n">train_loss_epoch</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
    
    <span class="n">avg_train_loss</span> <span class="o">=</span> <span class="n">jnp</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">jnp</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">train_loss_epoch</span><span class="p">))</span>
    <span class="n">train_losses</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">avg_train_loss</span><span class="p">)</span>

    <span class="c1"># Validation loop
</span>    <span class="n">val_loss_epoch</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">val_images</span><span class="p">),</span> <span class="n">batch_size</span><span class="p">):</span>
        <span class="n">batch_images</span> <span class="o">=</span> <span class="n">jnp</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">val_images</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">])</span>
        <span class="n">batch_labels</span> <span class="o">=</span> <span class="n">jnp</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">val_labels_onehot</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">])</span>
        <span class="n">val_loss</span> <span class="o">=</span> <span class="nf">loss_fn</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">batch_images</span><span class="p">,</span> <span class="n">batch_labels</span><span class="p">)</span>
        <span class="n">val_loss_epoch</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">val_loss</span><span class="p">)</span>

    <span class="n">avg_val_loss</span> <span class="o">=</span> <span class="n">jnp</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">jnp</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">val_loss_epoch</span><span class="p">))</span>
    <span class="n">val_losses</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">avg_val_loss</span><span class="p">)</span>
    
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Epoch </span><span class="si">{</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="si">}</span><span class="s">, Train Loss: </span><span class="si">{</span><span class="n">avg_train_loss</span><span class="si">}</span><span class="s">, Val Loss: </span><span class="si">{</span><span class="n">avg_val_loss</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>

    <span class="c1"># Save best model
</span>    <span class="k">if</span> <span class="n">avg_val_loss</span> <span class="o">&lt;</span> <span class="n">best_val_loss</span><span class="p">:</span>
        <span class="n">best_val_loss</span> <span class="o">=</span> <span class="n">avg_val_loss</span>
        <span class="n">best_params</span> <span class="o">=</span> <span class="n">params</span>

<span class="c1"># Calculate the training time with JAX
</span><span class="n">end_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span>
<span class="n">jax_training_time</span> <span class="o">=</span> <span class="n">end_time</span> <span class="o">-</span> <span class="n">start_time</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Training time with JAX: </span><span class="si">{</span><span class="n">jax_training_time</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s"> seconds</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># Save the best model parameters to a file
</span><span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="sh">'</span><span class="s">best_model_params.pkl</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">wb</span><span class="sh">'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">pickle</span><span class="p">.</span><span class="nf">dump</span><span class="p">(</span><span class="n">best_params</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
</code></pre></div></div> <p>Then, we can plot the training and validation loss like below:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">train_losses</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Train Loss</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">val_losses</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Validation Loss</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Epochs</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Loss</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/jax-performance-mnist-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/jax-performance-mnist-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/jax-performance-mnist-1400.webp"/> <img src="/assets/img/jax-performance-mnist.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Figure 2. The plot of training and validation loss using JAX framework on MNIST dataset </div> <p>And that’s it! You’ve built a simple CNN for MNIST digit classification using JAX and Flax. Now, to get the point on why using those frameworks can be really crucial, let’s compare its training time with the training time when using tensorflow. Note that we measured the time taken to train a Convolutional Neural Network (CNN) on the MNIST dataset using both JAX and TensorFlow. For fair comparison, both models have the same architecture and are trained for the same number of epochs and batch size.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
<span class="kn">from</span> <span class="n">tensorflow.keras</span> <span class="kn">import</span> <span class="n">layers</span><span class="p">,</span> <span class="n">models</span>

<span class="c1"># Preparing data
</span><span class="p">(</span><span class="n">train_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">),</span> <span class="p">(</span><span class="n">val_images</span><span class="p">,</span> <span class="n">val_labels</span><span class="p">)</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">.</span><span class="n">mnist</span><span class="p">.</span><span class="nf">load_data</span><span class="p">()</span>
<span class="n">train_images</span> <span class="o">=</span> <span class="n">train_images</span><span class="p">.</span><span class="nf">reshape</span><span class="p">((</span><span class="mi">60000</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">)).</span><span class="nf">astype</span><span class="p">(</span><span class="sh">'</span><span class="s">float32</span><span class="sh">'</span><span class="p">)</span> <span class="o">/</span> <span class="mi">255</span>
<span class="n">val_images</span> <span class="o">=</span> <span class="n">val_images</span><span class="p">.</span><span class="nf">reshape</span><span class="p">((</span><span class="mi">10000</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">)).</span><span class="nf">astype</span><span class="p">(</span><span class="sh">'</span><span class="s">float32</span><span class="sh">'</span><span class="p">)</span> <span class="o">/</span> <span class="mi">255</span>

<span class="n">train_labels</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="nf">to_categorical</span><span class="p">(</span><span class="n">train_labels</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">val_labels</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="nf">to_categorical</span><span class="p">(</span><span class="n">val_labels</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

<span class="c1"># Creating the model
</span><span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">([</span>
    <span class="n">layers</span><span class="p">.</span><span class="nc">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">relu</span><span class="sh">'</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
    <span class="n">layers</span><span class="p">.</span><span class="nc">AveragePooling2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span>
    <span class="n">layers</span><span class="p">.</span><span class="nc">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">relu</span><span class="sh">'</span><span class="p">),</span>
    <span class="n">layers</span><span class="p">.</span><span class="nc">AveragePooling2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span>
    <span class="n">layers</span><span class="p">.</span><span class="nc">Flatten</span><span class="p">(),</span>
    <span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">relu</span><span class="sh">'</span><span class="p">),</span>
    <span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">softmax</span><span class="sh">'</span><span class="p">)</span>
<span class="p">])</span>

<span class="c1"># Compiling the model
</span><span class="n">model</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="sh">'</span><span class="s">adam</span><span class="sh">'</span><span class="p">,</span>
              <span class="n">loss</span><span class="o">=</span><span class="sh">'</span><span class="s">categorical_crossentropy</span><span class="sh">'</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">accuracy</span><span class="sh">'</span><span class="p">])</span>

<span class="c1"># Measuring time for training
</span><span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span>

<span class="c1"># Fitting the model
</span><span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span>
    <span class="n">train_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
    <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">val_images</span><span class="p">,</span> <span class="n">val_labels</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">end_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span>

<span class="n">non_jax_training_time</span> <span class="o">=</span> <span class="n">end_time</span> <span class="o">-</span> <span class="n">start_time</span>

<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Training time without JAX: </span><span class="si">{</span><span class="n">non_jax_training_time</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s"> seconds</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <p>In machine learning, training time is a crucial factor. Faster training allows for more iterations and experiments, speeding up the development process. Below is a bar graph that shows the training time for each framework.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Labels and corresponding values
</span><span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">JAX</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">TensorFlow</span><span class="sh">'</span><span class="p">]</span>
<span class="n">times</span> <span class="o">=</span> <span class="p">[</span><span class="n">jax_training_time</span><span class="p">,</span> <span class="n">non_jax_training_time</span><span class="p">]</span>

<span class="c1"># Create the bar chart
</span><span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">barh</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">times</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">blue</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">green</span><span class="sh">'</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Training Time (seconds)</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Training Time Comparison: JAX vs TensorFlow</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">grid</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="sh">'</span><span class="s">x</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># Annotate with the exact times
</span><span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">time</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">times</span><span class="p">):</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">text</span><span class="p">(</span><span class="n">time</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="sa">f</span><span class="sh">'</span><span class="si">{</span><span class="n">time</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s"> s</span><span class="sh">'</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="sh">'</span><span class="s">center</span><span class="sh">'</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/jax-flax-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/jax-flax-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/jax-flax-1400.webp"/> <img src="/assets/img/jax-flax.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Figure 1. JAX vs. Tensorflow Speed Performance on Simple MNIST Image Classification Dataset </div> <p>As you can see, using JAX in simple dataset like MNIST can increase the speed significantly. You can imagine how fast it is when implementing it in bigger datasets and much more complex tasks!!</p> <h3 id="conclusion">Conclusion</h3> <p>JAX and Flax are powerful tools for machine learning research and projects. JAX provides fast and flexible numerical operations, while Flax offers a simple and extendable way to build neural networks.</p> <p>I hope this post helps you understand the basics of JAX and Flax. Below I also attach runned jupyter notebook about this blogpost. Happy coding!</p> <div class="jupyter-notebook" style="position: relative; width: 100%; margin: 0 auto;"> <div class="jupyter-notebook-iframe-container"> <iframe src="/assets/jupyter/Jax_and_Flax_Intro.ipynb.html" style="position: absolute; top: 0; left: 0; border-style: none;" width="100%" height="100%" onload="this.parentElement.style.paddingBottom = (this.contentWindow.document.documentElement.scrollHeight + 10) + 'px'"></iframe> </div> </div>]]></content><author><name></name></author><category term="blogpost"/><category term="JAX,"/><category term="Flax,"/><category term="Deep"/><category term="Learning"/><category term="Frameworks"/><summary type="html"><![CDATA[Understanding JAX and Flax!]]></summary></entry><entry><title type="html">Prompt Learning with Optimal Transport Presentation Slides</title><link href="ravialdy/ravialdy.github.io/slides/2023/07/31/plot-paper-review.html" rel="alternate" type="text/html" title="Prompt Learning with Optimal Transport Presentation Slides"/><published>2023-07-31T12:57:00+00:00</published><updated>2023-07-31T12:57:00+00:00</updated><id>ravialdy/ravialdy.github.io/slides/2023/07/31/plot-paper-review</id><content type="html" xml:base="ravialdy/ravialdy.github.io/slides/2023/07/31/plot-paper-review.html"><![CDATA[<p>Here is the presentation slides when I did paper review about Prompt Learning with Optimal Transport paper.</p> <p><a href="/assets/pdf/(Ravialdy) Review about Prompt Learning with Optimal Transport.pdf">Download Slides</a></p>]]></content><author><name></name></author><category term="slides"/><category term="prompt"/><category term="learning,"/><category term="optimal"/><category term="transport"/><summary type="html"><![CDATA[Here is the presentation slides that I have created when explaining about Prompt Learning with Optimal Transport paper.]]></summary></entry><entry><title type="html">Visual Prompting For Adversarial Robustness Presentation Slides</title><link href="ravialdy/ravialdy.github.io/slides/2023/07/29/cavp-paper-review.html" rel="alternate" type="text/html" title="Visual Prompting For Adversarial Robustness Presentation Slides"/><published>2023-07-29T12:57:00+00:00</published><updated>2023-07-29T12:57:00+00:00</updated><id>ravialdy/ravialdy.github.io/slides/2023/07/29/cavp-paper-review</id><content type="html" xml:base="ravialdy/ravialdy.github.io/slides/2023/07/29/cavp-paper-review.html"><![CDATA[<p>Here is the presentation slides when I did paper review about Visual Prompting For Adversarial Robustness paper.</p> <p><a href="/assets/pdf/(Ravialdy) Paper Review of Visual Prompting For Adversarial Robustness, Current Progress, and Next Plan.pdf">Download Slides</a></p>]]></content><author><name></name></author><category term="slides"/><category term="black-box"/><category term="model,"/><category term="visual"/><category term="prompting,"/><category term="adversarial"/><category term="attack"/><summary type="html"><![CDATA[Here is the presentation slides that I have created when explaining about Visual Prompting For Adversarial Robustness paper.]]></summary></entry><entry><title type="html">Black-Box Visual Prompting for Robust Transfer Learning Presentation Slides</title><link href="ravialdy/ravialdy.github.io/slides/2023/07/27/blackvip-paper-review.html" rel="alternate" type="text/html" title="Black-Box Visual Prompting for Robust Transfer Learning Presentation Slides"/><published>2023-07-27T12:57:00+00:00</published><updated>2023-07-27T12:57:00+00:00</updated><id>ravialdy/ravialdy.github.io/slides/2023/07/27/blackvip-paper-review</id><content type="html" xml:base="ravialdy/ravialdy.github.io/slides/2023/07/27/blackvip-paper-review.html"><![CDATA[<p>Here is the presentation slides when I did paper review about Black-Box Visual Prompting for Robust Transfer Learning (BlackVIP) paper.</p> <p><a href="/assets/pdf/(Ravialdy) Paper Review about BlackVIP_Black-Box Visual Prompting for Robust Transfer Learning.pdf">Download Slides</a></p>]]></content><author><name></name></author><category term="slides"/><category term="black-box"/><category term="model,"/><category term="visual"/><category term="prompting"/><summary type="html"><![CDATA[Here is the presentation slides that I have created when explaining about Black-Box Visual Prompting for Robust Transfer Learning paper.]]></summary></entry><entry><title type="html">Black-box Adversarial Reprogramming Presentation Slides</title><link href="ravialdy/ravialdy.github.io/slides/2023/07/26/bar-paper-review.html" rel="alternate" type="text/html" title="Black-box Adversarial Reprogramming Presentation Slides"/><published>2023-07-26T12:57:00+00:00</published><updated>2023-07-26T12:57:00+00:00</updated><id>ravialdy/ravialdy.github.io/slides/2023/07/26/bar-paper-review</id><content type="html" xml:base="ravialdy/ravialdy.github.io/slides/2023/07/26/bar-paper-review.html"><![CDATA[<p>Here is the presentation slides when I did paper review about Black-box Adversarial Reprogramming (BAR) paper.</p> <p><a href="/assets/pdf/(Ravialdy) Paper Review about Black-box Adversarial Reprogramming.pdf">Download Slides</a></p>]]></content><author><name></name></author><category term="slides"/><category term="adversarial,"/><category term="attack,"/><category term="black-box"/><category term="model"/><summary type="html"><![CDATA[Here is the presentation slides that I have created when explaining about Black-box Adversarial Reprogramming paper.]]></summary></entry><entry><title type="html">Visual ChatGPT Presentation Slides</title><link href="ravialdy/ravialdy.github.io/slides/2023/07/25/jupyter-notebook.html" rel="alternate" type="text/html" title="Visual ChatGPT Presentation Slides"/><published>2023-07-25T12:57:00+00:00</published><updated>2023-07-25T12:57:00+00:00</updated><id>ravialdy/ravialdy.github.io/slides/2023/07/25/jupyter-notebook</id><content type="html" xml:base="ravialdy/ravialdy.github.io/slides/2023/07/25/jupyter-notebook.html"><![CDATA[<p>Here is the presentation slides that I have created when explaining about Visual ChatGPT paper.</p> <p><a href="/assets/pdf/Paper Review _Visual ChatGPT.pdf">Download Slides</a></p>]]></content><author><name></name></author><category term="slides"/><category term="ChatGPT,"/><category term="GPT-4,"/><category term="Large"/><category term="Language"/><category term="Model"/><category term="(LLM)"/><summary type="html"><![CDATA[Here is the presentation slides that I have created when explaining about Visual ChatGPT paper.]]></summary></entry><entry><title type="html">GPT-4 Presentation Slides</title><link href="ravialdy/ravialdy.github.io/slides/2023/07/12/post-bibliography.html" rel="alternate" type="text/html" title="GPT-4 Presentation Slides"/><published>2023-07-12T13:56:00+00:00</published><updated>2023-07-12T13:56:00+00:00</updated><id>ravialdy/ravialdy.github.io/slides/2023/07/12/post-bibliography</id><content type="html" xml:base="ravialdy/ravialdy.github.io/slides/2023/07/12/post-bibliography.html"><![CDATA[<p>Here is the presentation slides that I have created when explaining about GPT-4. You can download the slides below if you are interested with that topic :)</p> <p><a href="/assets/pdf/Paper Review _GPT-4.pdf">Download Slides</a></p>]]></content><author><name></name></author><category term="slides"/><category term="GPT-4,"/><category term="Large"/><category term="Language"/><category term="Model"/><category term="(LLM),"/><category term="Reinforcement"/><category term="Learning"/><category term="from"/><category term="Human"/><category term="Feedback"/><category term="(RLHF)"/><summary type="html"><![CDATA[Here is the presentation slides that I have created when explaining about GPT-4. You can download the slides below if you are interested with that topic :)]]></summary></entry><entry><title type="html">Proximal Policy Optimization (PPO) Presentation Slides</title><link href="ravialdy/ravialdy.github.io/slides/2023/05/12/custom-blockquotes.html" rel="alternate" type="text/html" title="Proximal Policy Optimization (PPO) Presentation Slides"/><published>2023-05-12T19:53:00+00:00</published><updated>2023-05-12T19:53:00+00:00</updated><id>ravialdy/ravialdy.github.io/slides/2023/05/12/custom-blockquotes</id><content type="html" xml:base="ravialdy/ravialdy.github.io/slides/2023/05/12/custom-blockquotes.html"><![CDATA[<p>Below is the presentation slides that I have created when explaining about Proximal Policy Optimization (PPO) paper.</p> <p><a href="/assets/pdf/(Ravialdy) Paper Review-Proximal Policy Optimization 1.pdf">Download Slides</a></p>]]></content><author><name></name></author><category term="slides"/><category term="Proximal"/><category term="Policy"/><category term="Optimization"/><category term="(PPO),"/><category term="Reinforcement"/><category term="Learning,"/><category term="Policy"/><category term="Gradient"/><summary type="html"><![CDATA[Presentation slides that I have created when explaining about Proximal Policy Optimization (PPO) paper.]]></summary></entry></feed>