<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Grad-CAM Demystified, Understanding the Magic Behind Visual Explanations in Neural Networks | Ravialdy's Blog</title> <meta name="author" content="Ravialdy Hidayat"> <meta name="description" content="Experienced AI Researcher and Data Scientist with over 3 years of experience in computer vision, machine learning, and AI model deployment. Passionate about solving complex problems and advancing the state of technology. "> <meta name="keywords" content="AI Research, Data Science, Computer Vision, Model Deployment, Machine Learning"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link href="/assets/css/bootstrap-toc.min.css?6f5af0bb9aab25d79b2448143cbeaa88" rel="stylesheet"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="ravialdy/ravialdy.github.io/blog/2023/gradcam-howitworks/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/">Ravialdy's Blog</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/assets/pdf/CV_Ravialdy%20(October%202023)%20(3).pdf" target="_blank">cv</a> </li> <li class="nav-item "> <a class="nav-link" href="/_pages/cv/">cv</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="row"> <div class="col-sm-3"> <nav id="toc-sidebar" class="sticky-top"></nav> </div> <div class="col-sm-9"> <div class="post"> <header class="post-header"> <h1 class="post-title">Grad-CAM Demystified, Understanding the Magic Behind Visual Explanations in Neural Networks</h1> <p class="post-meta">October 20, 2023</p> <p class="post-tags"> <a href="/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a>   ·   <a href="/blog/tag/computer"> <i class="fas fa-hashtag fa-sm"></i> Computer</a>   <a href="/blog/tag/vision"> <i class="fas fa-hashtag fa-sm"></i> Vision</a>   <a href="/blog/tag/cv"> <i class="fas fa-hashtag fa-sm"></i> (CV),</a>   <a href="/blog/tag/gradcam"> <i class="fas fa-hashtag fa-sm"></i> GradCAM,</a>   <a href="/blog/tag/visualization"> <i class="fas fa-hashtag fa-sm"></i> Visualization</a>     ·   <a href="/blog/category/blogpost"> <i class="fas fa-tag fa-sm"></i> blogpost</a>   </p> </header> <article class="post-content"> <div id="table-of-contents"> <ul id="toc" class="section-nav"> <li class="toc-entry toc-h2"><a href="#introduction">Introduction</a></li> <li class="toc-entry toc-h2"><a href="#what-is-grad-cam">What is Grad-CAM?</a></li> <li class="toc-entry toc-h2"><a href="#the-core-idea">The Core Idea</a></li> <li class="toc-entry toc-h2"> <a href="#how-does-it-work-in-quite-detail">How Does it Work in Quite Detail?</a> <ul> <li class="toc-entry toc-h3"><a href="#step-1-backward-pass">Step 1: Backward Pass</a></li> <li class="toc-entry toc-h3"><a href="#step-2-average-pooling">Step 2: Average Pooling</a></li> <li class="toc-entry toc-h3"><a href="#step-3-weighted-sum">Step 3: Weighted Sum</a></li> <li class="toc-entry toc-h3"><a href="#step-4-relu-activation">Step 4: ReLU Activation</a></li> <li class="toc-entry toc-h3"><a href="#step-5-understanding-the-heatmap">Step 5: Understanding the Heatmap</a></li> </ul> </li> <li class="toc-entry toc-h2"> <a href="#a-simple-pytorch-grad-cam-implementation">A Simple PyTorch Grad-CAM Implementation</a> <ul> <li class="toc-entry toc-h3"><a href="#import-libraries">Import Libraries</a></li> <li class="toc-entry toc-h3"><a href="#load-pretrained-model">Load Pretrained Model</a></li> <li class="toc-entry toc-h3"><a href="#utility-function-to-get-model-features-and-gradients">Utility Function to Get Model Features and Gradients</a></li> <li class="toc-entry toc-h3"><a href="#generate-grad-cam-heatmap">Generate Grad-CAM Heatmap</a></li> <li class="toc-entry toc-h3"><a href="#function-to-overlay-heatmap-on-original-image">Function to Overlay Heatmap on Original Image</a></li> <li class="toc-entry toc-h3"><a href="#function-to-visualize-heatmap">Function to Visualize Heatmap</a></li> <li class="toc-entry toc-h3"><a href="#putting-it-all-together">Putting it All Together</a></li> </ul> </li> <li class="toc-entry toc-h2"><a href="#conclusion">Conclusion</a></li> </ul> </div> <hr> <div id="markdown-content"> <style>h2{margin-top:1.25em;margin-bottom:.5em}h3{margin-top:1em;margin-bottom:.5em}</style> <h2 id="introduction">Introduction</h2> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/gradcam/gradcam_our_result-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/gradcam/gradcam_our_result-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/gradcam/gradcam_our_result-1400.webp"></source> <img src="/assets/img/gradcam/gradcam_our_result.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Figure 1. Grad-CAM visualization that we will implement in this blogpost. </div> <p>Convolutional Neural Networks (CNNs) are amazing. They can recognize cats in pictures, help self-driving cars see, and even beat humans at games. But what most people see about neural networks is this, they’re like magic boxes: data goes in, and the answer comes out, without knowing what happens in between. So, how do we know what part of an image the network finds important for its decision? Introducing Grad-CAM method, a technique that helps us “see” what the network is looking at.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/gradcam/GradCAM-Example-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/gradcam/GradCAM-Example-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/gradcam/GradCAM-Example-1400.webp"></source> <img src="/assets/img/gradcam/GradCAM-Example.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Figure 2. Example of how Grad-CAM visualization shows the important part for the model's decision on different classes (Image source : <a href="https://github.com/kazuto1011/grad-cam-pytorch" rel="external nofollow noopener" target="_blank">Kazuto</a>). </div> <h2 id="what-is-grad-cam">What is Grad-CAM?</h2> <p>Grad-CAM stands for Gradient-weighted Class Activation Mapping. Why the name is like that? In short, we use gradient to help us understand how neural networks behave in certain circumstances, while activation here is analogous with the level of excitement or interest the neural network has when it comes to certain features used in recognizing the important part in the image (we will discuss in detail about it later). How it does that? Basically, Grad-CAM will create what we call a “heatmap.” Imagine you have your cat picture. Now, think of putting a see-through red paper over it. This red paper will have some areas darker and some areas lighter. The darker areas show where the neural network looked the most. Maybe the network looked a lot at the cat’s eyes and a little at the tail. This heatmap will help you “see” what parts of the picture made the neural network decide it’s looking at a cat. It’s like the network is saying, “Look, I think this is a cat because of these parts of the picture.”</p> <h2 id="the-core-idea">The Core Idea</h2> <p>Grad-CAM will use something called “gradients” which can tell us how much each neuron’s activity would need to change in order to affect the final decision (class scores or logits that are output by the neural network) of the model. The key intuition here is that if the gradient is large in magnitude, a small change in the neuron’s activity will have a significant impact on the final decision. Conversely, if the gradient is small, the neuron’s contribution to the final decision is relatively minor. Grad-CAM also often uses deeper layers in order to visualize important part of the image. In a CNN, the early layers usually can only understand simple things like edges or colors. The deeper you go, the more complex the things they understand, like ears or whiskers. Grad-CAM focuses on the last set of these layers because they understand both the important details (like whiskers) and the bigger picture (like the shape of a cat). Remember that in the context of CNN, feature maps in the early layers of can only capture basic features like edges and textures. But, as you move deeper into the network, the feature maps begin to assemble these into more complex structures, capturing higher-level features like shapes, patterns, and even entire objects in some cases.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/gradcam/deeplearning_featuremaps-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/gradcam/deeplearning_featuremaps-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/gradcam/deeplearning_featuremaps-1400.webp"></source> <img src="/assets/img/gradcam/deeplearning_featuremaps.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Figure 3. Illustration of how CNN and common NN architecture can learn more complex features as the layer goes deeper (Image source : <a href="https://julien-vitay.net/lecturenotes-neurocomputing/3-deeplearning/3-CNN.html" rel="external nofollow noopener" target="_blank">Julien Vitay</a>). </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/gradcam/gradcam_different_layers-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/gradcam/gradcam_different_layers-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/gradcam/gradcam_different_layers-1400.webp"></source> <img src="/assets/img/gradcam/gradcam_different_layers.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Figure 4. Illustration of the effect of deeper layers towards Grad-CAM visualization (Image source : Selvaraju et al, 2017 [1]). </div> <h2 id="how-does-it-work-in-quite-detail">How Does it Work in Quite Detail?</h2> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/gradcam/gradcam_detail_works-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/gradcam/gradcam_detail_works-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/gradcam/gradcam_detail_works-1400.webp"></source> <img src="/assets/img/gradcam/gradcam_detail_works.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Figure 5. Overview Grad-CAM architecture (Image source : Selvaraju et al, 2017 [1]). </div> <h3 id="step-1-backward-pass">Step 1: Backward Pass</h3> <p>First, we need to find out how much each part of our image contributed to the final decision. So, we go backward through the network, from the output (“this is a cat”) toward the input image. As we go back, we calculate something called gradients. Remember that the “gradient” of a neuron with respect to the final decision can give us a measure of sensitivity. Specifically, it tells us how much the final output (e.g., the probability score for the class “cat”) would change if the activity of that particular neuron were to change by a small amount. In mathematical terms, if \(y\) is the final output and \(A_{ij}^k\) is the activation of neuron \(k\) at position \((i, j)\) in some layer, then \(\frac{\partial y}{\partial A_{ij}^k}\) is the gradient that tells us the rate of change of \(y\) with respect to \(A_{ij}^k\).</p> <h3 id="step-2-average-pooling">Step 2: Average Pooling</h3> <p>We then average these gradients across the spatial dimensions (width and height) of each feature map. This gives us a single number for each feature map, which we call the “importance weight.”</p> <p>The math looks like this:</p> \[\alpha_{k}^{c} = \frac{1}{Z} \sum_{i} \sum_{j} \frac{\partial y^{c}}{\partial A_{i j}^{k}}\] <p>Here, \(\alpha_{k}^{c}\) is the importance weight for feature map \(k\) when identifying class \(c\).</p> <h3 id="step-3-weighted-sum">Step 3: Weighted Sum</h3> <p>Next, we take a weighted sum of our original feature maps, using these importance weights. This gives us a rough heatmap. We will explain that in more detail about how it is used in the step 5.</p> \[L_{\text{Grad-CAM}}^{c} = \text{ReLU}\left(\sum_{k} \alpha_{k}^{c} A^{k}\right)\] <h3 id="step-4-relu-activation">Step 4: ReLU Activation</h3> <p>Finally, we apply a ReLU (Rectified Linear Unit) function to this heatmap. Why? Because we’re only interested in the parts of the image that positively influence the final decision.</p> <h3 id="step-5-understanding-the-heatmap">Step 5: Understanding the Heatmap</h3> <p>At this point, you might wonder, “How exactly does the weighted sum of feature maps and ReLU activation contribute to generating a heatmap?”</p> <p>The heatmap \(L_{\text{Grad-CAM}}^{c}\) is essentially a 2D spatial map of the image that highlights the important regions, which have been “weighted” based on their contribution to the class score. Recall that this weighted sum can be formally represented as:</p> \[L_{\text{Grad-CAM}}^{c} = \text{ReLU}\left(\sum_{k} \alpha_{k}^{c} A^{k}\right)\] <p>Here, \(\alpha_{k}^{c}\) serves as a weight indicating the importance of feature map \(A^{k}\) for the particular class \(c\). So, when we multiply \(\alpha_{k}^{c}\) with the feature map \(A^{k}\), we’re essentially weighing the feature map based on its importance for class \(c\).</p> <p>After the weighted sum, we apply the ReLU non-linearity function. Why ReLU? This is to ensure that only the features that have a positive influence on the class of interest are kept. ReLU zeroes out negative values, leaving only the positive regions that are important for identifying the specific class. The ReLU function can be represented mathematically as:</p> \[\text{ReLU}(x) = \max(0, x)\] <p>Thus, the heatmap generated is a filtered version of the weighted sum of feature maps, where only the ‘positively contributing’ features are illuminated. This enables you to see which regions in the image were pivotal in making the final class decision.</p> <h2 id="a-simple-pytorch-grad-cam-implementation">A Simple PyTorch Grad-CAM Implementation</h2> <p>To see Grad-CAM in action, let’s walk through a straightforward example using PyTorch. We’ll use a pretrained VGG16 model for this demonstration.</p> <p>First, make sure to install PyTorch if you haven’t already.</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip <span class="nb">install </span>torch torchvision
</code></pre></div></div> <h3 id="import-libraries">Import Libraries</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">torch</span>
<span class="kn">import</span> <span class="n">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="n">torchvision.models</span> <span class="k">as</span> <span class="n">models</span>
<span class="kn">import</span> <span class="n">torchvision.transforms</span> <span class="k">as</span> <span class="n">transforms</span>
<span class="kn">from</span> <span class="n">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
</code></pre></div></div> <h3 id="load-pretrained-model">Load Pretrained Model</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Load a pretrained VGG16 model
</span><span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="p">.</span><span class="nf">vgg16</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>
</code></pre></div></div> <h3 id="utility-function-to-get-model-features-and-gradients">Utility Function to Get Model Features and Gradients</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">typing</span> <span class="kn">import</span> <span class="n">Tuple</span>

<span class="k">def</span> <span class="nf">get_features_gradients</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">]:</span>
    <span class="sh">"""</span><span class="s">
    Forward pass to get the features and register hook to get gradients.
    
    Parameters:
    - model (nn.Module): Neural network model
    - x (torch.Tensor): Input image tensor
    
    Returns:
    - features (torch.Tensor): Extracted features from the last convolutional layer
    - gradients (torch.Tensor): Gradients w.r.t the features
    </span><span class="sh">"""</span>
    <span class="n">features</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="n">gradients</span> <span class="o">=</span> <span class="bp">None</span>
    
    <span class="k">def</span> <span class="nf">hook_feature</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">output</span><span class="p">):</span>
        <span class="k">nonlocal</span> <span class="n">features</span>
        <span class="n">features</span> <span class="o">=</span> <span class="n">output</span><span class="p">.</span><span class="nf">detach</span><span class="p">()</span>
        
    <span class="k">def</span> <span class="nf">hook_gradient</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">):</span>
        <span class="k">nonlocal</span> <span class="n">gradients</span>
        <span class="n">gradients</span> <span class="o">=</span> <span class="n">grad_output</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">detach</span><span class="p">()</span>
        
    <span class="c1"># Register hooks
</span>    <span class="n">handle_forward</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">features</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">].</span><span class="nf">register_forward_hook</span><span class="p">(</span><span class="n">hook_feature</span><span class="p">)</span>
    <span class="n">handle_backward</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">features</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">].</span><span class="nf">register_backward_hook</span><span class="p">(</span><span class="n">hook_gradient</span><span class="p">)</span>
    
    <span class="c1"># Forward and backward pass
</span>    <span class="n">model</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>
    <span class="n">output</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="c1"># Class-specific backprop
</span>    <span class="n">output</span><span class="p">.</span><span class="nf">backward</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nc">Tensor</span><span class="p">([[</span><span class="mi">1</span> <span class="k">if</span> <span class="n">idx</span> <span class="o">==</span> <span class="mi">243</span> <span class="k">else</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">output</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])]]))</span>
    
    <span class="c1"># Remove hooks
</span>    <span class="n">handle_forward</span><span class="p">.</span><span class="nf">remove</span><span class="p">()</span>
    <span class="n">handle_backward</span><span class="p">.</span><span class="nf">remove</span><span class="p">()</span>
    
    <span class="k">return</span> <span class="n">features</span><span class="p">,</span> <span class="n">gradients</span>
</code></pre></div></div> <h3 id="generate-grad-cam-heatmap">Generate Grad-CAM Heatmap</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">typing</span> <span class="kn">import</span> <span class="n">Tuple</span>

<span class="k">def</span> <span class="nf">generate_grad_cam</span><span class="p">(</span><span class="n">features</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">gradients</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">image_shape</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Generate Grad-CAM heatmap.

    Parameters:
    - features (torch.Tensor): Extracted features from the last convolutional layer
    - gradients (torch.Tensor): Gradients w.r.t the features
    - image_shape (Tuple[int, int]): Original shape of the input image (height, width)

    Returns:
    - torch.Tensor: Grad-CAM heatmap
    </span><span class="sh">"""</span>
    <span class="c1"># Global average pooling on gradients to get neuron importance
</span>    <span class="n">alpha</span> <span class="o">=</span> <span class="n">gradients</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">keepdim</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

    <span class="c1"># Weighted sum of feature maps based on neuron importance
</span>    <span class="n">weighted_features</span> <span class="o">=</span> <span class="n">features</span> <span class="o">*</span> <span class="n">alpha</span>

    <span class="c1"># ReLU applied on weighted combination of feature maps
</span>    <span class="n">heatmap</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="nf">relu</span><span class="p">(</span><span class="n">weighted_features</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span>
    
    <span class="c1"># Resizing the heatmap to original image size
</span>    <span class="n">heatmap</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="nf">interpolate</span><span class="p">(</span><span class="n">heatmap</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">image_shape</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="sh">'</span><span class="s">bilinear</span><span class="sh">'</span><span class="p">,</span> <span class="n">align_corners</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">heatmap</span>
</code></pre></div></div> <h3 id="function-to-overlay-heatmap-on-original-image">Function to Overlay Heatmap on Original Image</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">cv2</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="n">typing</span> <span class="kn">import</span> <span class="n">Union</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="k">def</span> <span class="nf">overlay_heatmap_on_image</span><span class="p">(</span><span class="n">image</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">Image</span><span class="p">.</span><span class="n">Image</span><span class="p">],</span> 
                             <span class="n">heatmap</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">],</span> 
                             <span class="n">alpha</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Overlay the Grad-CAM heatmap on the original image.
    
    Parameters:
    - image (np.ndarray or PIL.Image): Original input image
    - heatmap (Union[np.ndarray, torch.Tensor]): Grad-CAM heatmap
    - alpha (float): Weight of the heatmap when overlaying
    
    Returns:
    - np.ndarray: Image with heatmap overlaid
    </span><span class="sh">"""</span>
    <span class="c1"># Convert PIL image to numpy array if necessary
</span>    <span class="k">if</span> <span class="nf">isinstance</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">Image</span><span class="p">.</span><span class="n">Image</span><span class="p">):</span>
        <span class="n">image</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
    
    <span class="c1"># Convert torch.Tensor to numpy array if necessary
</span>    <span class="k">if</span> <span class="nf">isinstance</span><span class="p">(</span><span class="n">heatmap</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="n">heatmap</span> <span class="o">=</span> <span class="n">heatmap</span><span class="p">.</span><span class="nf">numpy</span><span class="p">()</span>
    
    <span class="c1"># Normalize the heatmap and convert to RGB format
</span>    <span class="n">heatmap_normalized</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">normalize</span><span class="p">(</span><span class="n">heatmap</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mi">255</span><span class="p">,</span> <span class="n">norm_type</span><span class="o">=</span><span class="n">cv2</span><span class="p">.</span><span class="n">NORM_MINMAX</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">cv2</span><span class="p">.</span><span class="n">CV_8U</span><span class="p">)</span>
    <span class="n">heatmap_colored</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">applyColorMap</span><span class="p">(</span><span class="n">heatmap_normalized</span><span class="p">,</span> <span class="n">cv2</span><span class="p">.</span><span class="n">COLORMAP_JET</span><span class="p">)</span>
    
    <span class="c1"># Resize heatmap to match the image size
</span>    <span class="n">heatmap_resized</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">resize</span><span class="p">(</span><span class="n">heatmap_colored</span><span class="p">,</span> <span class="p">(</span><span class="n">image</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">image</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
    
    <span class="c1"># Overlay heatmap on image
</span>    <span class="n">overlayed</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">addWeighted</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">heatmap_resized</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">overlayed</span>
</code></pre></div></div> <h3 id="function-to-visualize-heatmap">Function to Visualize Heatmap</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">typing</span> <span class="kn">import</span> <span class="n">Union</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="k">def</span> <span class="nf">visualize_heatmap</span><span class="p">(</span><span class="n">image</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">Image</span><span class="p">.</span><span class="n">Image</span><span class="p">],</span> 
                      <span class="n">heatmap</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span> 
                      <span class="n">figsize</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Visualize the original image, the Grad-CAM heatmap, and the overlayed image.
    
    Parameters:
    - image (Union[np.ndarray, Image.Image]): The original input image.
    - heatmap (torch.Tensor): The Grad-CAM heatmap.
    - figsize (Tuple[int, int]): The size of the figure for plotting.
    
    Returns:
    - None
    </span><span class="sh">"""</span>
    <span class="c1"># Normalize the heatmap for visualization
</span>    <span class="n">heatmap_normalized</span> <span class="o">=</span> <span class="n">heatmap</span><span class="p">.</span><span class="nf">squeeze</span><span class="p">().</span><span class="nf">cpu</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span>
    <span class="n">heatmap_normalized</span> <span class="o">=</span> <span class="p">(</span><span class="n">heatmap_normalized</span> <span class="o">-</span> <span class="n">heatmap_normalized</span><span class="p">.</span><span class="nf">min</span><span class="p">())</span> <span class="o">/</span> <span class="p">(</span><span class="n">heatmap_normalized</span><span class="p">.</span><span class="nf">max</span><span class="p">()</span> <span class="o">-</span> <span class="n">heatmap_normalized</span><span class="p">.</span><span class="nf">min</span><span class="p">())</span>
    
    <span class="c1"># Overlay the heatmap on the original image
</span>    <span class="n">overlayed_image</span> <span class="o">=</span> <span class="nf">overlay_heatmap_on_image</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">heatmap_normalized</span><span class="p">)</span>
    
    <span class="c1"># Create the plot
</span>    <span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="n">figsize</span><span class="p">)</span>
    
    <span class="n">plt</span><span class="p">.</span><span class="nf">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Original Image</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">imshow</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">image</span><span class="p">))</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">axis</span><span class="p">(</span><span class="sh">'</span><span class="s">off</span><span class="sh">'</span><span class="p">)</span>
    
    <span class="n">plt</span><span class="p">.</span><span class="nf">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Grad-CAM Heatmap</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">imshow</span><span class="p">(</span><span class="n">heatmap_normalized</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="sh">'</span><span class="s">jet</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">axis</span><span class="p">(</span><span class="sh">'</span><span class="s">off</span><span class="sh">'</span><span class="p">)</span>
    
    <span class="n">plt</span><span class="p">.</span><span class="nf">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Overlayed Image</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">imshow</span><span class="p">(</span><span class="n">cv2</span><span class="p">.</span><span class="nf">cvtColor</span><span class="p">(</span><span class="n">overlayed_image</span><span class="p">,</span> <span class="n">cv2</span><span class="p">.</span><span class="n">COLOR_BGR2RGB</span><span class="p">))</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">axis</span><span class="p">(</span><span class="sh">'</span><span class="s">off</span><span class="sh">'</span><span class="p">)</span>
    
    <span class="n">plt</span><span class="p">.</span><span class="nf">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div> <h3 id="putting-it-all-together">Putting it All Together</h3> <p>Now, let’s apply Grad-CAM on an example image.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Load and preprocess an example image (here, 'bull_mastiff.jpg' is an example image file)
</span><span class="n">input_image</span> <span class="o">=</span> <span class="n">Image</span><span class="p">.</span><span class="nf">open</span><span class="p">(</span><span class="sh">"</span><span class="s">/content/bull_mastiff.jpg</span><span class="sh">"</span><span class="p">).</span><span class="nf">resize</span><span class="p">((</span><span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">))</span>
<span class="n">preprocess</span> <span class="o">=</span> <span class="n">transforms</span><span class="p">.</span><span class="nc">Compose</span><span class="p">([</span>
    <span class="n">transforms</span><span class="p">.</span><span class="nc">ToTensor</span><span class="p">(),</span>
    <span class="n">transforms</span><span class="p">.</span><span class="nc">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="p">[</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">],</span> <span class="n">std</span><span class="o">=</span><span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">]),</span>
<span class="p">])</span>
<span class="n">input_tensor</span> <span class="o">=</span> <span class="nf">preprocess</span><span class="p">(</span><span class="n">input_image</span><span class="p">).</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Get features and gradients
</span><span class="n">features</span><span class="p">,</span> <span class="n">gradients</span> <span class="o">=</span> <span class="nf">get_features_gradients</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">input_tensor</span><span class="p">)</span>

<span class="c1"># Generate Grad-CAM heatmap
</span><span class="n">image_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">input_image</span><span class="p">.</span><span class="n">height</span><span class="p">,</span> <span class="n">input_image</span><span class="p">.</span><span class="n">width</span><span class="p">)</span>
<span class="n">heatmap</span> <span class="o">=</span> <span class="nf">generate_grad_cam</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">gradients</span><span class="p">,</span> <span class="n">image_shape</span><span class="p">)</span>

<span class="c1"># Visualize the heatmap
</span><span class="nf">visualize_heatmap</span><span class="p">(</span><span class="n">input_image</span><span class="p">,</span> <span class="n">heatmap</span><span class="p">)</span>
</code></pre></div></div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/gradcam/gradcam_our_result-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/gradcam/gradcam_our_result-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/gradcam/gradcam_our_result-1400.webp"></source> <img src="/assets/img/gradcam/gradcam_our_result.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Figure 6. Grad-CAM visualization result. </div> <p>In this example, we focused on the ‘bull mastiff’ class, which corresponds to index 243 in the ImageNet dataset. You can replace this with the index for any other class you’re interested in.</p> <h2 id="conclusion">Conclusion</h2> <p>Grad-CAM is like understanding how exactly neural networks make a decision. It allows the network to tell us, “Hey, I think this is a cat because of these whiskers and this tail.” And it does this all without requiring any change to the existing model architecture and retraining the model, making it a powerful tool for understanding these complex networks.</p> <p>I hope this blog post has demystified Grad-CAM for you. It’s a very good visualization method that can explain the decision of complex neural networks, letting us see what’s happening under the hood.</p> </div> </article> <h2>References</h2> <div class="publications"> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 abbr"></div> <div id="GradCAM" class="col-sm-8"> <div class="title">Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization</div> <div class="author"> </div> <div class="periodical"> <em>IEEE/CVF International Conference on Computer Vision (ICCV)</em>, 2017 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/pdf/1610.02391.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> </div> </div> </li></ol> </div> <div id="giscus_thread" style="max-width: 800px; margin: 0 auto;"> <script>let giscusTheme=localStorage.getItem("theme"),giscusAttributes={src:"https://giscus.app/client.js","data-repo":"alshedivat/al-folio","data-repo-id":"MDEwOlJlcG9zaXRvcnk2MDAyNDM2NQ==","data-category":"Comments","data-category-id":"DIC_kwDOA5PmLc4CTBt6","data-mapping":"title","data-strict":"1","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"bottom","data-theme":giscusTheme,"data-lang":"en",crossorigin:"anonymous",async:""},giscusScript=document.createElement("script");Object.entries(giscusAttributes).forEach(([t,a])=>giscusScript.setAttribute(t,a)),document.getElementById("giscus_thread").appendChild(giscusScript);</script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> </div> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2023 Ravialdy Hidayat. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="/assets/js/bootstrap-toc.min.js?c82ff4de8b0955d6ff14f5b05eed7eb6"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>